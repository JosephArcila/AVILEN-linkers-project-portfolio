{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# トピックのユーザー入力を求める\n",
        "topic = input(\"研究トピックを入力してください: \")"
      ],
      "metadata": {
        "id": "Jcd9OD2ZDOXF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4da5e6a6-e481-4fba-c09c-814977a49195"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "研究トピックを入力してください: 熱・風以外の方法で髪の毛を乾かす技術のトレンドを教えて\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdX6zIMXFi84"
      },
      "source": [
        "# WEB-学術研究 (STORM)\n",
        "\n",
        "[STORM](https://arxiv.org/abs/2402.14207) は、Shao氏らによって設計された研究アシスタントで、より充実した記事生成のために「アウトライン駆動型RAG」の考えを拡張したものです。\n",
        "\n",
        "STORMは、ユーザーが提供したトピックについてWikipediaスタイルの記事を生成するように設計されています。より体系的で包括的な記事を作成するために、以下の2つの主要な洞察を適用します：\n",
        "\n",
        "1. 類似トピックを検索してアウトライン（計画）を作成することで、カバレッジを向上させる\n",
        "2. 多視点的で検索に基づく会話シミュレーションにより、参考文献数と情報密度を高める\n",
        "\n",
        "制御フローは以下の図のようになります。\n",
        "\n",
        "STORMには以下の主要なステージがあります：\n",
        "\n",
        "1. 初期アウトラインの生成 + 関連テーマの調査\n",
        "2. 異なる視点の特定\n",
        "3. 「専門家へのインタビュー」（ロールプレイングLLM）\n",
        "4. アウトラインの改善（参考文献を使用）\n",
        "5. セクションの執筆、そして記事の執筆\n",
        "\n",
        "専門家インタビューのステージは、ロールプレイする記事執筆者と研究専門家の間で行われます。「専門家」は外部知識を検索し、的確な質問に回答することができ、引用元をベクトルストアに保存して、後の改善段階で完全な記事を統合できるようにします。\n",
        "\n",
        "（潜在的に）無限の研究範囲を制限するために設定できるハイパーパラメータがいくつかあります：\n",
        "\n",
        "N: 調査/使用する視点の数（ステップ2->3）\n",
        "M: ステップでの最大会話ターン数（ステップ3）\n",
        "\n",
        "## セットアップ\n",
        "\n",
        "まず、必要なパッケージをインストールしてAPIキーを設定します"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ichytgiFi86"
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install -U langchain_community langchain_openai langchain_fireworks langgraph wikipedia duckduckgo-search tavily-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "from openai import OpenAI\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "def _set_env(var: str):\n",
        "    if os.environ.get(var):\n",
        "        return\n",
        "    os.environ[var] = getpass.getpass(var + \":\")\n",
        "\n",
        "# OpenAlexメールアドレスの入力を求める\n",
        "openalex_email = getpass.getpass(\"OpenAlexメールアドレスを入力してください: \")\n",
        "os.environ[\"OPENALEX_EMAIL\"] = openalex_email\n",
        "\n",
        "# API認証情報の入力を求める\n",
        "api_key = getpass.getpass(\"OpenAI APIキーを入力してください: \")\n",
        "base_url = getpass.getpass(\"ベースURLを入力してください: \")\n",
        "\n",
        "# クライアントの初期化\n",
        "client = OpenAI(base_url=base_url, api_key=api_key)"
      ],
      "metadata": {
        "id": "TNCdMdAvtjTj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0a4cb84-bd24-4c5c-f39c-2f66a7191a1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAlexメールアドレスを入力してください: ··········\n",
            "OpenAI APIキーを入力してください: ··········\n",
            "ベースURLを入力してください: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbNaX7XBFi87"
      },
      "source": [
        "### LLMの選択"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qn4AfQe6Fi87"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "model = \"openai.gpt-4o-mini\"\n",
        "llm = ChatOpenAI(openai_api_base=base_url, openai_api_key=api_key, model=model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJrUZIdvFi88"
      },
      "source": [
        "## 初期アウトラインの生成\n",
        "\n",
        "多くのトピックについて、LLMは重要な関連トピックの初期アイデアを持っています。研究後に改良される\n",
        "初期アウトラインを生成することができます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mFHCHU4KFi89"
      },
      "outputs": [],
      "source": [
        "from typing import List, Optional\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "direct_gen_outline_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"あなたはWikipediaの執筆者です。ユーザーが提供したトピックについてのWikipediaページの概要を作成してください。包括的かつ具体的に書いてください。\",\n",
        "        ),\n",
        "        (\"user\", \"{topic}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "class Subsection(BaseModel):\n",
        "    subsection_title: str = Field(..., title=\"小節のタイトル\")\n",
        "    description: str = Field(..., title=\"小節の内容\")\n",
        "\n",
        "    @property\n",
        "    def as_str(self) -> str:\n",
        "        return f\"### {self.subsection_title}\\n\\n{self.description}\".strip()\n",
        "\n",
        "\n",
        "class Section(BaseModel):\n",
        "    section_title: str = Field(..., title=\"節のタイトル\")\n",
        "    description: str = Field(..., title=\"節の内容\")\n",
        "    subsections: Optional[List[Subsection]] = Field(\n",
        "        default=None,\n",
        "        title=\"Wikipediaページの各小節のタイトルと説明\",\n",
        "    )\n",
        "\n",
        "    @property\n",
        "    def as_str(self) -> str:\n",
        "        subsections = \"\\n\\n\".join(\n",
        "            f\"### {subsection.subsection_title}\\n\\n{subsection.description}\"\n",
        "            for subsection in self.subsections or []\n",
        "        )\n",
        "        return f\"## {self.section_title}\\n\\n{self.description}\\n\\n{subsections}\".strip()\n",
        "\n",
        "\n",
        "class Outline(BaseModel):\n",
        "    page_title: str = Field(..., title=\"Wikipediaページのタイトル\")\n",
        "    sections: List[Section] = Field(\n",
        "        default_factory=list,\n",
        "        title=\"Wikipediaページの各節のタイトルと説明\",\n",
        "    )\n",
        "\n",
        "    @property\n",
        "    def as_str(self) -> str:\n",
        "        sections = \"\\n\\n\".join(section.as_str for section in self.sections)\n",
        "        return f\"# {self.page_title}\\n\\n{sections}\".strip()\n",
        "\n",
        "\n",
        "generate_outline_direct = direct_gen_outline_prompt | llm.with_structured_output(\n",
        "    Outline\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "initial_outline = generate_outline_direct.invoke({\"topic\": topic})\n",
        "\n",
        "print(initial_outline.as_str)"
      ],
      "metadata": {
        "id": "ByEgd8aT0820",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97537aa9-c5e4-492a-f70f-b530c3f5d84a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# 熱・風以外の髪の毛を乾かす技術\n",
            "\n",
            "## 概要\n",
            "\n",
            "髪の毛を乾かす方法は、主に熱と風を利用するものが一般的ですが、近年ではそれ以外の干渉技術が注目されています。これらの新しい技術は、髪へのダメージを減少させ、より髪の健康を考慮したアプローチを提供します。特に低温や無風での乾燥方法が注目されています。これらは特に敏感な髪質やダメージが気になる人々に適しています。さらに、環境への配慮から省エネルギーでの乾燥方法にも需要が高まっています。　実際にこれらの技術は、日常生活における使い方や、商品展開にも影響を与えています。.\n",
            "\n",
            "### 水分蒸発を促進する技術\n",
            "\n",
            "特殊な素材を使用したタオルやマイクロファイバーで、髪の水分を素早く吸収し、化学的に髪を乾かす技術が徐々に普及しています。これにより、熱や風を使わなくても髪を効果的に乾かすことが可能となります。\n",
            "\n",
            "### しずく軽減技術\n",
            "\n",
            "新しい乾燥機能を持つヘアケア製品のいくつかは、髪に残ったしずくを軽減する技術を使っています。これにより、毛髪の表面から水分が早く除去され、乾燥時間を短縮する効果があります。\n",
            "\n",
            "### 超音波技術\n",
            "\n",
            "超音波波動を利用して、髪の内部に微細な気泡を生成し、その振動によって水分を蒸発させる技術が研究されています。これにより、髪に優しい方法でスピーディーに乾かすことが期待されています。\n",
            "\n",
            "### エコ乾燥法\n",
            "\n",
            "環境意識の高まりに伴い、電力を使わずに自然の流れや温度を利用して乾燥する技術も注目されています。例えば、風通しの良い場所で自然乾燥させる方法に加え、新しいデザインのドライシャンプーなども取り入れられています。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUNBYYbZFi89"
      },
      "source": [
        "## トピックの展開\n",
        "\n",
        "言語モデルはパラメータ内にWikipedia的な知識を保持していますが、検索エンジンを使用して関連する最新の情報を取り入れることでより良い結果が得られます。\n",
        "\n",
        "Wikipediaから取得した関連トピックのリストを生成することから検索を開始します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vl5oVV5BFi89"
      },
      "outputs": [],
      "source": [
        "gen_related_topics_prompt = ChatPromptTemplate.from_template(\n",
        "    \"\"\"以下のトピックについてWikipediaページを執筆しています。関連する主題のWikipediaページを特定し、推奨してください。このトピックに一般的に関連する興味深い側面についての洞察を提供する例や、類似トピックのWikipediaページに含まれる典型的な内容と構造を理解するのに役立つ例を探しています。\n",
        "できるだけ多くの関連主題とURLを列挙してください。\n",
        "対象トピック: {topic}\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "\n",
        "class RelatedSubjects(BaseModel):\n",
        "    topics: List[str] = Field(\n",
        "        description=\"背景調査のための関連主題の包括的なリスト\",\n",
        "    )\n",
        "\n",
        "\n",
        "expand_chain = gen_related_topics_prompt | llm.with_structured_output(\n",
        "    RelatedSubjects\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "related_subjects = await expand_chain.ainvoke({\"topic\": topic})\n",
        "related_subjects"
      ],
      "metadata": {
        "id": "WyalBoYE04LB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d80db6ac-cfc1-4bcc-9fb4-aaf3d11045fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RelatedSubjects(topics=['ドライヤー', '髪の毛の乾燥方法', '髪の毛のスタイリング技術', 'エコフレンドリーな美容技術', '髪の毛ケア製品のトレンド', 'ヘアサロンのサービス', '自宅での髪の毛ケア', '乾燥機の技術革新', '日本における髪の美容文化', '温風以外の髪の乾燥技術', 'ヘアケアの歴史', '空気乾燥技術'])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKRj8liMFi8-"
      },
      "source": [
        "## 視点の生成\n",
        "\n",
        "これらの関連テーマから、異なる背景と所属を持つ「専門家」としてWikipedia編集者の代表を選択することができます。\n",
        "これにより検索プロセスを分散させ、より総合的な最終レポートの作成を促進します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPxmeDI5Fi8-"
      },
      "outputs": [],
      "source": [
        "class Editor(BaseModel):\n",
        "    affiliation: str = Field(\n",
        "        description=\"編集者の主な所属\",\n",
        "    )\n",
        "    name: str = Field(\n",
        "        description=\"編集者の名前\", pattern=r\"^[a-zA-Z0-9_-]{1,64}$\"\n",
        "    )\n",
        "    role: str = Field(\n",
        "        description=\"トピックに関連する編集者の役割\",\n",
        "    )\n",
        "    description: str = Field(\n",
        "        description=\"編集者の焦点、関心事、動機の説明\",\n",
        "    )\n",
        "\n",
        "    @property\n",
        "    def persona(self) -> str:\n",
        "        return f\"名前: {self.name}\\n役割: {self.role}\\n所属: {self.affiliation}\\n説明: {self.description}\\n\"\n",
        "\n",
        "\n",
        "class Perspectives(BaseModel):\n",
        "    editors: List[Editor] = Field(\n",
        "        description=\"編集者とその役割、所属の包括的なリスト\",\n",
        "        # 編集者の数をM以下に制限するpydanticバリデーション/制限を追加\n",
        "    )\n",
        "\n",
        "\n",
        "gen_perspectives_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"\"\"トピックについて包括的な記事を作成するために協力して作業する、多様で個性的なWikipedia編集者グループを選定する必要があります。各編集者は、このトピックに関連する異なる視点、役割、所属を代表します。\\\n",
        "\n",
        "    着想を得るために、関連トピックの他のWikipediaページを参考にすることができます。各編集者について、何に焦点を当てるかの説明を追加してください。\n",
        "\n",
        "    着想を得るための関連トピックのWikiページの概要：\n",
        "\n",
        "    {examples}\"\"\",\n",
        "        ),\n",
        "        (\"user\", \"対象トピック: {topic}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "gen_perspectives_chain = (\n",
        "    gen_perspectives_prompt\n",
        "    | ChatOpenAI(\n",
        "        openai_api_base=base_url,\n",
        "        openai_api_key=api_key,\n",
        "        model=\"openai.gpt-3.5-turbo\"\n",
        "    ).with_structured_output(\n",
        "        Perspectives,\n",
        "        method=\"function_calling\"\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7vwy3o4NFi8-"
      },
      "outputs": [],
      "source": [
        "from langchain_community.retrievers import WikipediaRetriever\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "from langchain_core.runnables import chain as as_runnable\n",
        "\n",
        "wikipedia_retriever = WikipediaRetriever(load_all_available_meta=True, top_k_results=1)\n",
        "\n",
        "\n",
        "def format_doc(doc, max_length=1000):\n",
        "    related = \"- \".join(doc.metadata[\"categories\"])\n",
        "    return f\"### {doc.metadata['title']}\\n\\n概要: {doc.page_content}\\n\\n関連\\n{related}\"[\n",
        "        :max_length\n",
        "        ]\n",
        "\n",
        "\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(format_doc(doc) for doc in docs)\n",
        "\n",
        "\n",
        "@as_runnable\n",
        "async def survey_subjects(topic: str):\n",
        "    related_subjects = await expand_chain.ainvoke({\"topic\": topic})\n",
        "    retrieved_docs = await wikipedia_retriever.abatch(\n",
        "        related_subjects.topics, return_exceptions=True\n",
        "    )\n",
        "    all_docs = []\n",
        "    for docs in retrieved_docs:\n",
        "        if isinstance(docs, BaseException):\n",
        "            continue\n",
        "        all_docs.extend(docs)\n",
        "    formatted = format_docs(all_docs)\n",
        "    return await gen_perspectives_chain.ainvoke({\"examples\": formatted, \"topic\": topic})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "perspectives = await survey_subjects.ainvoke(topic)"
      ],
      "metadata": {
        "id": "iqlNdj1n0wVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "perspectives.dict()"
      ],
      "metadata": {
        "id": "ZzSKgs910wJr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0f28829-ff19-4275-a630-cbba1ae77990"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-b975437d5130>:1: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  perspectives.dict()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'editors': [{'affiliation': 'Hair Salon Association',\n",
              "   'name': 'MiaS',\n",
              "   'role': 'Hair Stylist',\n",
              "   'description': 'MiaSは専門家の美容師であり、熱・風以外の方法で髪の毛を乾かす技術の最新トレンドや効果的な方法に関心があります。彼女は常に新しいヘアケア技術に興味を持っており、その情報を共有することで他の美容師や顧客に役立てています。'},\n",
              "  {'affiliation': 'Fashion Magazine',\n",
              "   'name': 'AveryT',\n",
              "   'role': 'Fashion Journalist',\n",
              "   'description': 'AveryTはファッション雑誌のジャーナリストで、最新の美容トレンドやヘアケアに関する記事を執筆しています。彼女は熱・風以外の髪の毛を乾かす技術についての情報収集とトレンド分析に情熱を持っています。'},\n",
              "  {'affiliation': 'Beauty Tech Startup',\n",
              "   'name': 'EthanH',\n",
              "   'role': 'Tech Innovator',\n",
              "   'description': 'EthanHは美容テックスタートアップのイノベーターであり、新しい技術やデバイスを開発しています。彼は熱・風以外の髪の毛を乾かす技術に革新的なアプローチをもたらすことに興味があります。'}]}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sg3y97AUFi8-"
      },
      "source": [
        "## 専門家との対話\n",
        "\n",
        "各Wikipedia編集者は、上記の視点を使用してロールプレイを行うよう準備されています。検索エンジンにアクセスできる第二の「専門家」に一連の質問を行います。これにより、改良されたアウトラインと更新された参考文献インデックスを生成するためのコンテンツを生成します。\n",
        "\n",
        "\n",
        "### インタビューの状態\n",
        "\n",
        "会話は循環的なので、独自のグラフ内に構築します。この状態にはメッセージ、参考文献、エディター（独自の「ペルソナ」を持つ）が含まれ、これらの会話を並列化しやすくします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZujehgOJFi8_"
      },
      "outputs": [],
      "source": [
        "from typing import Annotated\n",
        "\n",
        "from langchain_core.messages import AnyMessage\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langgraph.graph import END, StateGraph, START\n",
        "\n",
        "\n",
        "def add_messages(left, right):\n",
        "    if not isinstance(left, list):\n",
        "        left = [left]\n",
        "    if not isinstance(right, list):\n",
        "        right = [right]\n",
        "    return left + right\n",
        "\n",
        "\n",
        "def update_references(references, new_references):\n",
        "    if not references:\n",
        "        references = {}\n",
        "    references.update(new_references)\n",
        "    return references\n",
        "\n",
        "\n",
        "def update_editor(editor, new_editor):\n",
        "    # 開始時にのみ設定可能\n",
        "    if not editor:\n",
        "        return new_editor\n",
        "    return editor\n",
        "\n",
        "\n",
        "class InterviewState(TypedDict):\n",
        "    messages: Annotated[List[AnyMessage], add_messages]\n",
        "    references: Annotated[Optional[dict], update_references]\n",
        "    editor: Annotated[Optional[Editor], update_editor]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQto3oHgFi8_"
      },
      "source": [
        "#### 対話の役割\n",
        "\n",
        "グラフには2人の参加者がいます：割り当てられた役割に基づいて質問をするWikipedia編集者（`generate_question`）と、検索エンジンを使用して可能な限り正確に質問に回答する専門家（`gen_answer_chain`）です。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5RPEc-WFi8_"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import AIMessage, HumanMessage, ToolMessage\n",
        "from langchain_core.prompts import MessagesPlaceholder\n",
        "\n",
        "gen_qn_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"\"\"あなたは経験豊富なWikipedia編集者で、特定のページを編集したいと考えています。\n",
        "Wikipedia編集者としての立場に加えて、トピックを研究する際の特定の焦点があります。\n",
        "現在、専門家と情報を得るためにチャットをしています。有用な情報を得るために、良い質問をしてください。\n",
        "質問がなくなったら、「ご協力ありがとうございました！」と言って会話を終了してください。\n",
        "質問は一度に一つずつ行い、以前に尋ねた質問は繰り返さないでください。\n",
        "質問は執筆したいトピックに関連したものにしてください。\n",
        "包括的で好奇心を持って、専門家からできるだけ多くのユニークな洞察を得るようにしてください。\\\n",
        "あなたの特定の視点を忠実に守ってください：\n",
        "{persona}\"\"\",\n",
        "        ),\n",
        "        MessagesPlaceholder(variable_name=\"messages\", optional=True),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "def tag_with_name(ai_message: AIMessage, name: str):\n",
        "    ai_message.name = name\n",
        "    return ai_message\n",
        "\n",
        "\n",
        "def swap_roles(state: InterviewState, name: str):\n",
        "    converted = []\n",
        "    for message in state[\"messages\"]:\n",
        "        if isinstance(message, AIMessage) and message.name != name:\n",
        "            message = HumanMessage(**message.dict(exclude={\"type\"}))\n",
        "        converted.append(message)\n",
        "    return {\"messages\": converted}\n",
        "\n",
        "\n",
        "@as_runnable\n",
        "async def generate_question(state: InterviewState):\n",
        "    editor = state[\"editor\"]\n",
        "    gn_chain = (\n",
        "        RunnableLambda(swap_roles).bind(name=editor.name)\n",
        "        | gen_qn_prompt.partial(persona=editor.persona)\n",
        "        | llm\n",
        "        | RunnableLambda(tag_with_name).bind(name=editor.name)\n",
        "    )\n",
        "    result = await gn_chain.ainvoke(state)\n",
        "    return {\"messages\": [result]}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    HumanMessage(f\"では、{topic}について記事を書いているとおっしゃっていましたか？\")\n",
        "]\n",
        "question = await generate_question.ainvoke(\n",
        "    {\n",
        "        \"editor\": perspectives.editors[0],\n",
        "        \"messages\": messages,\n",
        "    }\n",
        ")\n",
        "\n",
        "question[\"messages\"][0].content"
      ],
      "metadata": {
        "id": "ny_ZmTCR0iKY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "d314dee9-c459-4ec7-b2c1-ca3a5e55681c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'はい、正確にその通りです。熱・風以外の方法で髪の毛を乾かす技術のトレンドに関心があります。その分野における最新の技術やトレンドについて詳しくお教えいただけますか？特に注目すべき製品や技術があれば教えてください。'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2Rbu-Q4Fi8_"
      },
      "source": [
        "#### 質問への回答\n",
        "\n",
        "`gen_answer_chain`は最初に編集者の質問に答えるためのクエリ（クエリ拡張）を生成し、その後引用付きで回答します。"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Queries(BaseModel):\n",
        "    queries: List[str] = Field(\n",
        "        description=\"ユーザーの質問に答えるための検索エンジンクエリの包括的なリスト\",\n",
        "    )\n",
        "    web_queries: List[str] = Field(\n",
        "        description=\"ユーザーの質問に答えるためのウェブ検索エンジンクエリの包括的なリスト\",\n",
        "    )\n",
        "    scholarly_queries: List[str] = Field(\n",
        "        description=\"ユーザーの質問に答えるための学術検索エンジンクエリの包括的なリスト\",\n",
        "    )\n",
        "\n",
        "    @classmethod\n",
        "    def create(cls, web_queries: List[str], scholarly_queries: List[str]):\n",
        "        return cls(\n",
        "            queries=web_queries + scholarly_queries,\n",
        "            web_queries=web_queries,\n",
        "            scholarly_queries=scholarly_queries\n",
        "        )\n",
        "\n",
        "# Model classes for each query type\n",
        "class WebQueries(BaseModel):\n",
        "    queries: List[str] = Field(description=\"ウェブ検索クエリ\")\n",
        "\n",
        "class ScholarlyQueries(BaseModel):\n",
        "    queries: List[str] = Field(description=\"学術検索クエリ\")\n",
        "\n",
        "# Simple, focused prompts for each type of search\n",
        "gen_web_queries_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\n",
        "        \"system\",\n",
        "        \"あなたは役立つリサーチアシスタントです。ユーザーの質問に答えるために検索エンジンにクエリを実行してください。\",\n",
        "    ),\n",
        "    MessagesPlaceholder(variable_name=\"messages\", optional=True),\n",
        "]) | llm.with_structured_output(WebQueries)\n",
        "\n",
        "gen_scholarly_queries_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\n",
        "        \"system\",\n",
        "        \"あなたは役立つリサーチアシスタントです。ユーザーの質問に答えるためにOpenAlex検索エンジンにクエリを実行してください。\",\n",
        "    ),\n",
        "    MessagesPlaceholder(variable_name=\"messages\", optional=True),\n",
        "]) | llm.with_structured_output(ScholarlyQueries)\n",
        "\n",
        "# Combine the chains\n",
        "from langchain.schema.runnable import RunnableParallel\n",
        "\n",
        "def combine_results(results):\n",
        "    return {\n",
        "        \"raw\": None,\n",
        "        \"parsed\": Queries.create(\n",
        "            web_queries=results[\"web\"].queries,\n",
        "            scholarly_queries=results[\"scholarly\"].queries\n",
        "        )\n",
        "    }\n",
        "\n",
        "gen_queries_chain = (\n",
        "    RunnableParallel({\n",
        "        \"web\": gen_web_queries_prompt,\n",
        "        \"scholarly\": gen_scholarly_queries_prompt\n",
        "    })\n",
        "    | combine_results\n",
        ")"
      ],
      "metadata": {
        "id": "Wqa6pW3C3SRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "queries = await gen_queries_chain.ainvoke(\n",
        "    {\"messages\": [HumanMessage(content=question[\"messages\"][0].content)]}\n",
        ")\n",
        "print(\"ウェブ検索クエリ\", queries[\"parsed\"].web_queries)\n",
        "print(\"学術検索クエリ\", queries[\"parsed\"].scholarly_queries)"
      ],
      "metadata": {
        "id": "tLpHMhYJ0b1R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c434076c-909d-4290-898f-673e3c6428bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ウェブ検索クエリ ['最新の髪の毛を乾かす技術', '非熱乾燥髪の毛 製品 トレンド 2023', '髪の毛 乾かす 技術 革新', '熱以外の方法 髪乾燥 最新', 'ノンドライヤー 髪の毛の乾かし方', '水分保持する髪の毛 乾燥方法 または製品', 'ミスト技術 髪の毛 乾かし方 2023', '外部データ 髪 乾燥 風以外 トレンド']\n",
            "学術検索クエリ ['最新の髪の毛乾燥技術', '熱以外の髪の毛乾燥方法', '風以外の髪の毛乾燥技術のトレンド', '髪の毛乾燥のための革新的な製品', '髪の毛乾燥における技術革新', '静電気を利用した髪の毛の乾燥技術', '髪の毛を乾かす新しいプロセス', '空気圧を活用したヘアドライ技術']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QtmZjNSkFi8_"
      },
      "outputs": [],
      "source": [
        "class AnswerWithCitations(BaseModel):\n",
        "    answer: str = Field(\n",
        "        description=\"ユーザーの質問に対する包括的な回答（引用付き）。\",\n",
        "    )\n",
        "    cited_urls: List[str] = Field(\n",
        "        description=\"回答内で引用されているURLのリスト。\",\n",
        "    )\n",
        "\n",
        "    @property\n",
        "    def as_str(self) -> str:\n",
        "        return f\"{self.answer}\\n\\nCitations:\\n\\n\" + \"\\n\".join(\n",
        "            f\"[{i+1}]: {url}\" for i, url in enumerate(self.cited_urls)\n",
        "        )\n",
        "\n",
        "\n",
        "gen_answer_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"\"\"あなたは情報を効果的に活用できる専門家です。あなたは、自分の知っているトピックについてWikipediaに記事を書きたいと考えているライターと会話をしています。関連情報を収集済みで、その情報を活用して回答を作成しようとしています。\n",
        "\n",
        "回答はできる限り情報量を多くし、収集した情報で裏付けられるようにしてください。\n",
        "すべての文は信頼できる情報源の引用（脚注形式）によって裏付けられている必要があります。回答の後にURLを再掲する形で引用を示してください。\"\"\",\n",
        "        ),\n",
        "        MessagesPlaceholder(variable_name=\"messages\", optional=True),\n",
        "    ]\n",
        ")\n",
        "\n",
        "gen_answer_chain = gen_answer_prompt | llm.with_structured_output(\n",
        "    AnswerWithCitations, include_raw=True\n",
        ").with_config(run_name=\"GenerateAnswer\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "from typing import List, Dict\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "class OpenAlexSearchAPIWrapper:\n",
        "    \"\"\"OpenAlex APIのラッパー。\"\"\"\n",
        "    def __init__(self, openalex_email: str = None):\n",
        "        self.openalex_email = openalex_email or os.getenv(\"OPENALEX_EMAIL\")\n",
        "\n",
        "    def _text(self, query: str) -> List[Dict]:\n",
        "        headers = {'User-Agent': f'mailto:{self.openalex_email}'}\n",
        "        url = \"https://api.openalex.org/works\"\n",
        "        params = {\n",
        "            \"search\": str(query),\n",
        "            \"per-page\": 25,  # Increased to ensure we get enough results with abstracts\n",
        "            \"page\": 1,\n",
        "            \"sort\": \"relevance_score:desc\",\n",
        "            \"select\": \"id,display_name,publication_year,abstract_inverted_index,doi,primary_location,cited_by_count\"\n",
        "        }\n",
        "\n",
        "        response = requests.get(url, params=params, headers=headers)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            data = response.json()\n",
        "            results = []\n",
        "            for work in data.get('results', []):\n",
        "                if not work:\n",
        "                    continue\n",
        "\n",
        "                # Skip if there's no abstract\n",
        "                if not work.get('abstract_inverted_index'):\n",
        "                    continue\n",
        "\n",
        "                # Process abstract\n",
        "                abstract_index = work['abstract_inverted_index']\n",
        "                word_positions = {pos: word for word, positions in abstract_index.items() for pos in positions}\n",
        "                abstract = \" \".join(word_positions[i] for i in sorted(word_positions.keys()))\n",
        "\n",
        "                # Skip if abstract is empty after processing\n",
        "                if not abstract.strip():\n",
        "                    continue\n",
        "\n",
        "                url = None\n",
        "                if work.get('doi'):\n",
        "                    url = f\"https://doi.org/{work['doi'].replace('https://doi.org/', '')}\"\n",
        "                elif work.get('primary_location', {}).get('doi'):\n",
        "                    url = f\"https://doi.org/{work['primary_location']['doi']}\"\n",
        "                elif work.get('id'):\n",
        "                    work_id = work['id'].replace('https://openalex.org/', '')\n",
        "                    url = f\"https://openalex.org/{work_id}\"\n",
        "\n",
        "                publication_year = work.get('publication_year', 'Year not available')\n",
        "                cited_by_count = work.get('cited_by_count', 0)\n",
        "\n",
        "                if url:\n",
        "                    results.append({\n",
        "                        \"content\": f\"Title: {work.get('display_name', '')}\\nYear: {publication_year}\\nCitations: {cited_by_count}\\nAbstract: {abstract}\",\n",
        "                        \"url\": url\n",
        "                    })\n",
        "\n",
        "                # Break once we have 5 results with abstracts\n",
        "                if len(results) == 5:\n",
        "                    break\n",
        "\n",
        "            return results\n",
        "        return []\n",
        "\n",
        "# 検索エンジンの初期化\n",
        "scholarly_search_engine = OpenAlexSearchAPIWrapper()\n",
        "\n",
        "@tool\n",
        "async def scholarly_search_engine(query: str):\n",
        "    \"\"\"学術研究のための検索エンジン。\"\"\"\n",
        "    results = OpenAlexSearchAPIWrapper()._text(query)\n",
        "    return results"
      ],
      "metadata": {
        "id": "byfplNS5Qs1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.utilities.duckduckgo_search import DuckDuckGoSearchAPIWrapper\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "# DDG\n",
        "web_search_engine = DuckDuckGoSearchAPIWrapper()\n",
        "\n",
        "\n",
        "@tool\n",
        "async def web_search_engine(query: str):\n",
        "    \"\"\"Search engine to the internet.\"\"\"\n",
        "    results = DuckDuckGoSearchAPIWrapper()._ddgs_text(query)\n",
        "    return [{\"content\": r[\"body\"], \"url\": r[\"href\"]} for r in results]"
      ],
      "metadata": {
        "id": "Fi5gBewhE9vQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dpScJ1wCFi8_"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from typing import Optional\n",
        "from langchain_core.runnables import RunnableConfig\n",
        "from langchain_core.messages import AIMessage, FunctionMessage, SystemMessage\n",
        "\n",
        "async def gen_scholarly_answer(\n",
        "    state: InterviewState,\n",
        "    queries,\n",
        "    config: Optional[RunnableConfig] = None,\n",
        "    name: str = \"Scholarly_Expert\",\n",
        "    max_str_len: int = 15000,\n",
        "):\n",
        "    print(\"Starting scholarly search...\")\n",
        "    swapped_state = swap_roles(state, name)\n",
        "\n",
        "    # Execute scholarly search\n",
        "    query_results = await scholarly_search_engine.abatch(\n",
        "        queries.scholarly_queries, config, return_exceptions=True\n",
        "    )\n",
        "\n",
        "    successful_results = [\n",
        "        res for res in query_results if not isinstance(res, Exception)\n",
        "    ]\n",
        "\n",
        "    all_query_results = {\n",
        "        res[\"url\"]: res[\"content\"] for results in successful_results for res in results\n",
        "    }\n",
        "\n",
        "    # Add search results to state for the answer generation\n",
        "    search_msg = SystemMessage(content=json.dumps(all_query_results)[:max_str_len])\n",
        "    swapped_state[\"messages\"].append(search_msg)\n",
        "\n",
        "    # Generate the answer using the collected information\n",
        "    generated = await gen_answer_chain.ainvoke(swapped_state)\n",
        "    cited_urls = set(generated[\"parsed\"].cited_urls)\n",
        "    cited_references = {k: v for k, v in all_query_results.items() if k in cited_urls}\n",
        "    formatted_content = generated[\"parsed\"].as_str\n",
        "\n",
        "    return {\n",
        "        \"content\": formatted_content,\n",
        "        \"references\": cited_references\n",
        "    }\n",
        "\n",
        "async def gen_web_answer(\n",
        "    state: InterviewState,\n",
        "    queries,\n",
        "    config: Optional[RunnableConfig] = None,\n",
        "    name: str = \"Web_Expert\",\n",
        "    max_str_len: int = 15000,\n",
        "):\n",
        "    print(\"Starting web search...\")\n",
        "    swapped_state = swap_roles(state, name)\n",
        "\n",
        "    query_results = await web_search_engine.abatch(\n",
        "        queries.web_queries, config, return_exceptions=True\n",
        "    )\n",
        "\n",
        "    successful_results = [\n",
        "        res for res in query_results if not isinstance(res, Exception)\n",
        "    ]\n",
        "\n",
        "    all_query_results = {\n",
        "        res[\"url\"]: res[\"content\"] for results in successful_results for res in results\n",
        "    }\n",
        "\n",
        "    # Add search results to state for the answer generation\n",
        "    search_msg = SystemMessage(content=json.dumps(all_query_results)[:max_str_len])\n",
        "    swapped_state[\"messages\"].append(search_msg)\n",
        "\n",
        "    # Generate the answer using the collected information\n",
        "    generated = await gen_answer_chain.ainvoke(swapped_state)\n",
        "    cited_urls = set(generated[\"parsed\"].cited_urls)\n",
        "    cited_references = {k: v for k, v in all_query_results.items() if k in cited_urls}\n",
        "    formatted_content = generated[\"parsed\"].as_str\n",
        "\n",
        "    return {\n",
        "        \"content\": formatted_content,\n",
        "        \"references\": cited_references\n",
        "    }\n",
        "\n",
        "async def gen_answer(\n",
        "    state: InterviewState,\n",
        "    config: Optional[RunnableConfig] = None,\n",
        "    max_str_len: int = 15000,\n",
        "):\n",
        "    # Generate queries once\n",
        "    queries = (await gen_queries_chain.ainvoke(state))[\"parsed\"]\n",
        "\n",
        "    # Get both scholarly and web answers using the same queries\n",
        "    scholarly_result = await gen_scholarly_answer(state, queries, config)\n",
        "    web_result = await gen_web_answer(state, queries, config)\n",
        "\n",
        "    # Combine both perspectives into a single message\n",
        "    combined_content = (\n",
        "        \"[Scholarly Works Perspective]\\n\" +\n",
        "        scholarly_result[\"content\"] +\n",
        "        \"\\n\\n---\\n\\n\" +\n",
        "        \"[Web Perspective]\\n\" +\n",
        "        web_result[\"content\"]\n",
        "    )\n",
        "\n",
        "    # Create single message with all citations\n",
        "    combined_message = AIMessage(\n",
        "        name=\"Combined_Expert\",\n",
        "        content=combined_content\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        \"messages\": [combined_message],\n",
        "        \"references\": {**scholarly_result[\"references\"], **web_result[\"references\"]}\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_answer = await gen_answer(\n",
        "    {\"messages\": [HumanMessage(content=question[\"messages\"][0].content)]}\n",
        ")\n",
        "example_answer[\"messages\"][-1].content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "uGpMsH6DGDvE",
        "outputId": "18cd40af-41ed-4a17-f964-acf79ec0928c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting scholarly search...\n",
            "Starting web search...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[Scholarly Works Perspective]\\n近年、髪の乾燥技術におけるトレンドとしては、熱や風以外の方法が注目を集めています。これには主に超音波乾燥、遠赤外線乾燥、さらには自然乾燥の技術が含まれます。これらの技術は、髪の健康を守りつつ、効率よく乾燥させることを目的としています。\\n\\n### 1. 超音波乾燥\\n超音波技術を用いた乾燥方法は、水分子を振動させることで熱を発生させ、髪の内部から外部に向けて水分を蒸発させるというものです。この技術は、髪へのダメージを減少させることができるため、特にダメージヘアの人々にとって魅力的です【1】。\\n\\n### 2. 遠赤外線乾燥\\n遠赤外線は、物質を加熱することなく、その内部から直接水分を蒸発させる能力を持っています。これにより、従来の乾燥方法に比べて、髪の毛を乾かす時間を短縮し、髪の質感を保持することが可能です。また、遠赤外線は抗菌作用もあるため、髪の健康を保つ助けにもなります【2】。\\n\\n### 3. 自然乾燥の技術\\n自然乾燥も進化しており、特に最近は、髪の毛が自然に乾くプロセスを助けるための製品が市場に登場しています。これには、髪を包み込む自然素材のタオルや、特定のセラムやオイルが含まれます。それらは髪に水分を閉じ込めながら、乾燥を促進する効果があります【3】。\\n\\n### 注目すべき製品\\n- **超音波ドライヤー**: 新しい超音波技術を搭載したドライヤーが登場し、髪のダメージを最小限に抑えることができます。\\n- **遠赤外線ヘアドライヤー**: このタイプのドライヤーは、髪の内部から乾かすため、熱ダメージのリスクを減少させます。\\n- **ライスウォーターエッセンス**: 日本の伝統的な髪の手入れ方法を基にしたこの製品は、髪をしっとりとさせる効果があり、最近特に人気を集めています【4】。\\n\\nこれらの技術や製品は、髪の仕上がりを保ちながら、より効果的に乾燥させる手助けをし、多くの人々が求める美しい髪の実現に寄与しています。\\n\\nCitations:\\n\\n[1]: https://doi.org/10.5650/jos1996.45.1133\\n[2]: https://doi.org/10.5107/sccj.25.33\\n[3]: https://doi.org/10.5107/sccj.44.29\\n\\n---\\n\\n[Web Perspective]\\n近年、髪の毛を熱や風以外の方法で乾かす技術が注目を集めています。特に、マイナスイオンや水分子の活用、静電気の排除など、新たな技術が進化しており、さまざまな製品が市場に登場しています。\\n\\n### 熱や風を使わない新技術\\n1. **マイナスイオン技術**: この技術は、髪のキューティクルを整えてツヤを出す効果があります。マイナスイオンを放出することで水分を吸収し、髪を冷やしながら乾燥させることが可能です。この方法は、髪が傷まず、しっかりと水分が保たれるため、髪のダメージを防ぎます【1】。\\n2. **超音波技術**: 超音波を利用したドライヤーは、髪の水分子を微細に分解し、素早く乾かします。この方法は、熱によるダメージを軽減し、髪の質感を保ちながら効率的に乾燥させます【2】。\\n3. **ジェル状ミスト技術**: 最近の製品では、髪を包み込むことができるジェル状のミストが登場しています。このミストは、髪の表面に水分を閉じ込めることで、乾燥時間を短縮しながらも、髪を保護する役割を果たします【3】。\\n\\n### 注目すべき製品\\n- **ダイソンのSupersonic Ionic**: これは、風量の調整が可能で、髪に負担をかけずに乾燥させることができる高性能なドライヤーです。特に湿気の多い環境での使用に適しています【4】。\\n- **高濃度ミストドライヤー「KINUJO」**: スチーム機能を備えたこの製品は、髪の内側から水分を補給しながら乾かすことができ、潤いを残します【5】。\\n- **静電気を防ぐ「BLOOM」**: 静電気を抑制するための特別なデザインが施されており、髪が広がるのを防ぎます。この製品は、特に冬場や乾燥する季節に最適です【6】。\\n\\n### 今後の展望\\n将来的には、さらなる技術革新が期待されています。例えば、自動温度調整やスマートセンサーを備えた製品が登場することで、個々の髪質や環境に合わせた最適な乾燥方法が提供されるでしょう。これにより、髪の健康を損なうことなく、より効果的に使用できる製品が増加することが予測されます【7】【8】。 \\n\\nこのような最新技術は、髪を傷めずに短時間で乾かすために進化しています。今後のトレンドとしては、環境配慮とユーザーの利便性が重視されるでしょう。\\n\\nCitations:\\n\\n[1]: https://tabitto.jp/hairdrye-quick-drying/\\n[2]: https://kurapick.com/dy_ib_sw/\\n[3]: https://www.kaiteki-navi.online/%E3%80%90%E6%9C%80%E6%96%B0%E3%81%AE%E3%83%89%E3%83%A9%E3%82%A4%E3%83%A4%E3%83%BC%E6%8A%80%E8%A1%93%E3%81%A8%E3%81%AF%EF%BC%9F%E3%80%91%E98A3%E5%87%A6%E3%82%B92%E3%80%80%E9%8A%AA%E5%B7%9D%E5%92%8C%E3%81%AF%E3%80%810%3C/%E3%81%A9%E3%82%8C%E3%82%92%E5%84%AA%E7%A7%BB%E3%82GRAPTER/LIBRARY/CLASSIC/CLASSIC.HTM\\n[4]: #4\\n[5]: https://www.abc-store-japan.com/diary- detail/561\\n[6]: https://kakakumag.com/seikatsu-kaden/?id=11218\\n[7]: https://note.com/tbola/n/n7e82daba4fe1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-upe6SLFi8_"
      },
      "source": [
        "#### インタビューグラフの構築\n",
        "\n",
        "編集者と専門家を定義したので、それらをグラフに組み合わせることができます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKE_jFUCFi9A"
      },
      "outputs": [],
      "source": [
        "max_num_turns = 5\n",
        "from langgraph.pregel import RetryPolicy\n",
        "\n",
        "\n",
        "def route_messages(state: InterviewState, name: str = \"Subject_Matter_Expert\"):\n",
        "    messages = state[\"messages\"]\n",
        "    num_responses = len(\n",
        "        [m for m in messages if isinstance(m, AIMessage) and m.name == name]\n",
        "    )\n",
        "    if num_responses >= max_num_turns:\n",
        "        return END\n",
        "    last_question = messages[-2]\n",
        "    if last_question.content.endswith(\"ご協力ありがとうございました！\"):\n",
        "        return END\n",
        "    return \"ask_question\"\n",
        "\n",
        "\n",
        "builder = StateGraph(InterviewState)\n",
        "\n",
        "builder.add_node(\"ask_question\", generate_question, retry=RetryPolicy(max_attempts=5))\n",
        "builder.add_node(\"answer_question\", gen_answer, retry=RetryPolicy(max_attempts=5))\n",
        "builder.add_conditional_edges(\"answer_question\", route_messages)\n",
        "builder.add_edge(\"ask_question\", \"answer_question\")\n",
        "\n",
        "builder.add_edge(START, \"ask_question\")\n",
        "interview_graph = builder.compile(checkpointer=False).with_config(\n",
        "    run_name=\"Conduct Interviews\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_step = None\n",
        "\n",
        "initial_state = {\n",
        "    \"editor\": perspectives.editors[0],\n",
        "    \"messages\": [\n",
        "        AIMessage(\n",
        "            content=f\"So you said you were writing an article on {topic}?\",\n",
        "            name=\"Subject_Matter_Expert\",\n",
        "        )\n",
        "    ],\n",
        "}\n",
        "async for step in interview_graph.astream(initial_state):\n",
        "    name = next(iter(step))\n",
        "    print(name)\n",
        "    print(\"-- \", str(step[name][\"messages\"])[:300])\n",
        "final_step = step"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5iAbksiE8DW",
        "outputId": "2dd40b3a-4fd5-43a6-a018-28a6f3cfb583"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-938fd75fcdcb>:32: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  message = HumanMessage(**message.dict(exclude={\"type\"}))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ask_question\n",
            "--  [AIMessage(content='そのトピックはとても興味深いですね！最近、熱や風以外の方法で髪を乾かす技術において注目されている革新的な手法や製品はありますか？特に、髪の健康に配慮した方法に焦点を当てているものがあれば教えていただけると嬉しいです。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 87, 'prompt_tokens': 352, 'total_tokens': 439, 'completion_tokens_details': \n",
            "Starting scholarly search...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-938fd75fcdcb>:32: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  message = HumanMessage(**message.dict(exclude={\"type\"}))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting web search...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-938fd75fcdcb>:32: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  message = HumanMessage(**message.dict(exclude={\"type\"}))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "answer_question\n",
            "--  [AIMessage(content='[Scholarly Works Perspective]\\n最近、熱や風を使わずに髪を乾かす技術が注目されています。これらの方法は特に髪の健康に配慮しており、以下のような最新トレンドがあります。\\n\\n1. **デジタルドライヤー**: 新しいタイプのドライヤーで、髪にやさしい温風を生成するものですが、風の強さをコントロールすることで、通常のドライヤーよりも髪のダメージを軽減します。これらのデバイスは、センサー技術を使用して、髪の質や湿度に応じた温度管理を行います[[1](https://www.example.com)].\\n\\n2. **水分蒸発技\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-938fd75fcdcb>:32: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  message = HumanMessage(**message.dict(exclude={\"type\"}))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ask_question\n",
            "--  [AIMessage(content='ありがとうございます！最近のトレンドや技術について非常に詳しく教えていただきました。これらの技術に関して、特に市場での人気や消費者の反応についてのデータはありますか？どの方法が最も注目されているのか、またそれらに対する需要の変化も知りたいです。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 82, 'prompt_tokens': 1874, 'total_tokens': 1956, 'completion_t\n",
            "Starting scholarly search...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-938fd75fcdcb>:32: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  message = HumanMessage(**message.dict(exclude={\"type\"}))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting web search...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-938fd75fcdcb>:32: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  message = HumanMessage(**message.dict(exclude={\"type\"}))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "answer_question\n",
            "--  [AIMessage(content='[Scholarly Works Perspective]\\n最近の熱や風以外の髪の毛を乾かす方法のトレンドに関する市場調査や消費者の反応について、いくつかのデータがあります。これらの技術は、特に髪の健康に配慮しているため、需要が高まりつつあります。以下に主な方法とその人気の状況をご紹介します。\\n\\n1. **デジタルドライヤー**: これらの製品は、多くの消費者に人気があります。センサー技術を用い、髪質や湿度に応じた温度管理が可能なため、一般的なドライヤーと比べて髪のダメージを減らすことができます。市場での売上は過去数年で急増しており、特に若い世代か\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-938fd75fcdcb>:32: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  message = HumanMessage(**message.dict(exclude={\"type\"}))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ask_question\n",
            "--  [AIMessage(content='ありがとうございます！とても具体的なデータとトレンドについてお話しいただき、非常に参考になりました。これらの情報をもとに、消費者のニーズに基づいた新しいヘアケア製品や技術をさらに深く理解することができそうです。\\n\\n最後に、これらの技術や方法が美容師としての業務にどのように影響を与えているか、または影響を与える可能性があると考えますか？美容師としての視点からの考察をお聞かせいただければ嬉しいです。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'com\n",
            "Starting scholarly search...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-938fd75fcdcb>:32: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  message = HumanMessage(**message.dict(exclude={\"type\"}))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting web search...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-938fd75fcdcb>:32: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  message = HumanMessage(**message.dict(exclude={\"type\"}))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "answer_question\n",
            "--  [AIMessage(content='[Scholarly Works Perspective]\\n最近の熱や風以外で髪を乾かす技術は、美容師の業務にさまざまな影響を与えています。特に、髪へのダメージを最小限に抑える技術が増えていることは、顧客の満足度を高める要因となっています。以下に、美容師としての視点から考えられる影響をいくつか挙げます。\\n\\n1. **顧客の髪への関心の高まり**: 消費者は髪の健康に対する関心が高くなり、新しい技術や製品に対する需要が増しています。美容師はこれを受けて、髪にやさしい乾燥方法やトリートメントを提供することで、より多くの顧客のニーズに応えなければなりませ\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-938fd75fcdcb>:32: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  message = HumanMessage(**message.dict(exclude={\"type\"}))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ask_question\n",
            "--  [AIMessage(content='ご協力ありがとうございました！', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 5602, 'total_tokens': 5608, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_predic\n",
            "Starting scholarly search...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-938fd75fcdcb>:32: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  message = HumanMessage(**message.dict(exclude={\"type\"}))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting web search...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-938fd75fcdcb>:32: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  message = HumanMessage(**message.dict(exclude={\"type\"}))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "answer_question\n",
            "--  [AIMessage(content='[Scholarly Works Perspective]\\n最近の髪の毛を乾かす技術や方法の発展は、美容師としての業務に多くの影響を及ぼしています。以下にその影響をまとめます。  \\n\\n1. **顧客ニーズの変化**: 現在の顧客は、髪の健康を重視する傾向が強まっており、熱や風以外で髪を乾かす技術の導入を求めています。美容師は、この変化に適応し、顧客の健康を守るために新しい技術や商品に精通する必要があります[[1](https://www.abc-store-japan.com/diary-detail/428)]。  \\n\\n2. **技術の進化に\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_state = next(iter(final_step.values()))"
      ],
      "metadata": {
        "id": "gKZQldcvFAp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sU9zpbEvFi9A"
      },
      "source": [
        "## アウトラインの改善\n",
        "\n",
        "STORMのこの段階で、様々な視点から多くの研究を行いました。これらの調査に基づいて元のアウトラインを改善する時が来ました。以下では、長いコンテキストウィンドウを持つLLMを使用してチェーンを作成し、元のアウトラインを更新します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CV_vUbDLFi9A"
      },
      "outputs": [],
      "source": [
        "refine_outline_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"\"\"あなたはWikipedia編集者です。専門家や検索エンジンから情報を収集しました。これから、Wikipediaページの概要を改善します。\n",
        "概要が包括的かつ具体的であることを確認してください。\n",
        "執筆するトピック: {topic}\n",
        "以前の概要:\n",
        "{old_outline}\"\"\",\n",
        "        ),\n",
        "        (\n",
        "            \"user\",\n",
        "            \"専門家との会話に基づいて概要を改善してください：\\n\\n会話内容：\\n\\n{conversations}\\n\\n改善されたWikipediaの概要を作成してください：\",\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "\n",
        "refine_outline_chain = refine_outline_prompt | llm.with_structured_output(\n",
        "    Outline\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82Q_Hl2UFi9D"
      },
      "source": [
        "## 記事の生成\n",
        "\n",
        "いよいよ完全な記事を生成する時が来ました。まず分割統治法を用いて、各セクションを個別のLLMが担当できるようにします。その後、長文形式のLLMを使用して完成した記事を改善します（各セクションが一貫性のない文体を使用している可能性があるため）。\n",
        "\n",
        "#### 検索機能の作成\n",
        "\n",
        "研究プロセスでは、最終的な記事執筆プロセスで検索したい可能性のある多数の参考文献が見つかります。\n",
        "\n",
        "まず、検索機能を作成します："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofugY0fLFi9D"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import InMemoryVectorStore\n",
        "from langchain_core.documents import Document\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(\n",
        "    openai_api_base=base_url,\n",
        "    openai_api_key=api_key,\n",
        "    model=\"openai.text-embedding-3-large\")\n",
        "reference_docs = [\n",
        "    Document(page_content=v, metadata={\"source\": k})\n",
        "    for k, v in final_state[\"references\"].items()\n",
        "]\n",
        "# このサイズのデータにはベクトルストアは実際には必要ありません。\n",
        "# 単なるnumpy行列でも良いですし、リクエスト間でドキュメントを\n",
        "# 保存することもできます。\n",
        "vectorstore = InMemoryVectorStore.from_documents(\n",
        "    reference_docs,\n",
        "    embedding=embeddings,\n",
        ")\n",
        "retriever = vectorstore.as_retriever(k=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIt9I4s8Fi9E"
      },
      "source": [
        "#### セクションの生成\n",
        "\n",
        "インデックス化された文書を使用してセクションを生成できるようになりました。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0aXmgr7Fi9E"
      },
      "outputs": [],
      "source": [
        "class SubSection(BaseModel):\n",
        "    subsection_title: str = Field(..., title=\"小節のタイトル\")\n",
        "    content: str = Field(\n",
        "        ...,\n",
        "        title=\"小節の完全な内容。関連する箇所には [#] の形式で出典を含めてください。\",\n",
        "    )\n",
        "\n",
        "    @property\n",
        "    def as_str(self) -> str:\n",
        "        return f\"### {self.subsection_title}\\n\\n{self.content}\".strip()\n",
        "\n",
        "\n",
        "class WikiSection(BaseModel):\n",
        "    section_title: str = Field(..., title=\"節のタイトル\")\n",
        "    content: str = Field(..., title=\"節の完全な内容\")\n",
        "    subsections: Optional[List[Subsection]] = Field(\n",
        "        default=None,\n",
        "        title=\"Wikipediaページの各小節のタイトルと説明\",\n",
        "    )\n",
        "    citations: List[str] = Field(default_factory=list)\n",
        "\n",
        "    @property\n",
        "    def as_str(self) -> str:\n",
        "        subsections = \"\\n\\n\".join(\n",
        "            subsection.as_str for subsection in self.subsections or []\n",
        "        )\n",
        "        citations = \"\\n\".join([f\" [{i}] {cit}\" for i, cit in enumerate(self.citations)])\n",
        "        return (\n",
        "            f\"## {self.section_title}\\n\\n{self.content}\\n\\n{subsections}\".strip()\n",
        "            + f\"\\n\\n{citations}\".strip()\n",
        "        )\n",
        "\n",
        "\n",
        "section_writer_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"あなたは熟練したWikipedia編集者です。以下の概要から割り当てられたWikiSectionを完成させてください：\\n\\n\"\n",
        "            \"{outline}\\n\\n以下の参考文献を用いて出典を記載してください：\\n\\n<Documents>\\n{docs}\\n<Documents>\",\n",
        "        ),\n",
        "        (\"user\", \"{section}セクションのWikiSectionを完全に執筆してください。\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "async def retrieve(inputs: dict):\n",
        "    docs = await retriever.ainvoke(inputs[\"topic\"] + \": \" + inputs[\"section\"])\n",
        "    formatted = \"\\n\".join(\n",
        "        [\n",
        "            f'<Document href=\"{doc.metadata[\"source\"]}\"/>\\n{doc.page_content}\\n</Document>'\n",
        "            for doc in docs\n",
        "        ]\n",
        "    )\n",
        "    return {\"docs\": formatted, **inputs}\n",
        "\n",
        "\n",
        "section_writer = (\n",
        "    retrieve\n",
        "    | section_writer_prompt\n",
        "    | llm.with_structured_output(WikiSection)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aasrxCx5Fi9E"
      },
      "source": [
        "#### 最終記事の生成\n",
        "\n",
        "ここで、すべての引用を適切にグループ化し、一貫した文体を維持するように草稿を書き直すことができます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0Gi83m3Fi9E"
      },
      "outputs": [],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "writer_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"\"\"あなたは熟練したWikipedia編集者です。以下のセクション原稿を使用して{topic}に関する完全なWiki記事を執筆してください：\\n\\n\n",
        "            {draft}\\n\\nWikipediaの形式ガイドラインに厳密に従ってください。\"\"\",\n",
        "        ),\n",
        "        (\n",
        "            \"user\",\n",
        "            \"\"\"マークダウン形式で完全なWiki記事を執筆してください。脚注は「[1]」のような形式で表記し、フッターで重複を避けてください。フッターにはURLを含めてください。\"\"\",\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "\n",
        "writer = writer_prompt | llm | StrOutputParser()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSzU_3TcFi9F"
      },
      "source": [
        "## 最終フロー\n",
        "\n",
        "全てを組み合わせる時が来ました。順序立てて6つの主要な段階があります：\n",
        ".\n",
        "1. 初期アウトライン + 視点の生成\n",
        "2. 記事のコンテンツを拡張するために各視点との一括会話\n",
        "3. 会話に基づいてアウトラインの改善\n",
        "4. 会話から参考文献のインデックス作成\n",
        "5. 記事の個別セクションの執筆\n",
        "6. 最終的なwikiの執筆\n",
        "\n",
        "この状態は各段階の出力を追跡します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zE2HV1ojFi9F"
      },
      "outputs": [],
      "source": [
        "class ResearchState(TypedDict):\n",
        "    topic: str\n",
        "    outline: Outline\n",
        "    editors: List[Editor]\n",
        "    interview_results: List[InterviewState]\n",
        "    # 最終セクションの出力\n",
        "    sections: List[WikiSection]\n",
        "    article: str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2WBAKtQsFi9F"
      },
      "outputs": [],
      "source": [
        "import asyncio\n",
        "\n",
        "\n",
        "async def initialize_research(state: ResearchState):\n",
        "    topic = state[\"topic\"]\n",
        "    coros = (\n",
        "        generate_outline_direct.ainvoke({\"topic\": topic}),\n",
        "        survey_subjects.ainvoke(topic),\n",
        "    )\n",
        "    results = await asyncio.gather(*coros)\n",
        "    return {\n",
        "        **state,\n",
        "        \"outline\": results[0],\n",
        "        \"editors\": results[1].editors,\n",
        "    }\n",
        "\n",
        "\n",
        "async def conduct_interviews(state: ResearchState):\n",
        "    topic = state[\"topic\"]\n",
        "    initial_states = [\n",
        "        {\n",
        "            \"editor\": editor,\n",
        "            \"messages\": [\n",
        "                AIMessage(\n",
        "                    content=f\"では、{topic}について記事を書いているとおっしゃっていましたか？\",\n",
        "                    name=\"Subject_Matter_Expert\",\n",
        "                )\n",
        "            ],\n",
        "        }\n",
        "        for editor in state[\"editors\"]\n",
        "    ]\n",
        "    # ここでは、インタビューを並列化するためにサブグラフを呼び出す。\n",
        "    interview_results = await interview_graph.abatch(initial_states)\n",
        "\n",
        "    return {\n",
        "        **state,\n",
        "        \"interview_results\": interview_results,\n",
        "    }\n",
        "\n",
        "\n",
        "def format_conversation(interview_state):\n",
        "    messages = interview_state[\"messages\"]\n",
        "    convo = \"\\n\".join(f\"{m.name}: {m.content}\" for m in messages)\n",
        "    return f'{interview_state[\"editor\"].name}との会話\\n\\n' + convo\n",
        "\n",
        "\n",
        "async def refine_outline(state: ResearchState):\n",
        "    convos = \"\\n\\n\".join(\n",
        "        [\n",
        "            format_conversation(interview_state)\n",
        "            for interview_state in state[\"interview_results\"]\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    updated_outline = await refine_outline_chain.ainvoke(\n",
        "        {\n",
        "            \"topic\": state[\"topic\"],\n",
        "            \"old_outline\": state[\"outline\"].as_str,\n",
        "            \"conversations\": convos,\n",
        "        }\n",
        "    )\n",
        "    return {**state, \"outline\": updated_outline}\n",
        "\n",
        "\n",
        "async def index_references(state: ResearchState):\n",
        "    all_docs = []\n",
        "    for interview_state in state[\"interview_results\"]:\n",
        "        reference_docs = [\n",
        "            Document(page_content=v, metadata={\"source\": k})\n",
        "            for k, v in interview_state[\"references\"].items()\n",
        "        ]\n",
        "        all_docs.extend(reference_docs)\n",
        "    await vectorstore.aadd_documents(all_docs)\n",
        "    return state\n",
        "\n",
        "\n",
        "async def write_sections(state: ResearchState):\n",
        "    outline = state[\"outline\"]\n",
        "    sections = await section_writer.abatch(\n",
        "        [\n",
        "            {\n",
        "                \"outline\": outline.as_str,\n",
        "                \"section\": section.section_title,\n",
        "                \"topic\": state[\"topic\"],\n",
        "            }\n",
        "            for section in outline.sections\n",
        "        ]\n",
        "    )\n",
        "    return {\n",
        "        **state,\n",
        "        \"sections\": sections,\n",
        "    }\n",
        "\n",
        "async def write_article(state: ResearchState):\n",
        "    topic = state[\"topic\"]\n",
        "    sections = state[\"sections\"]\n",
        "    draft = \"\\n\\n\".join([section.as_str for section in sections])\n",
        "    article = await writer.ainvoke({\"topic\": topic, \"draft\": draft})\n",
        "    return {\n",
        "        **state,\n",
        "        \"article\": article,\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z17SORjjFi9F"
      },
      "source": [
        "#### グラフの作成"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUKT5welFi9F"
      },
      "outputs": [],
      "source": [
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "builder = StateGraph(ResearchState)\n",
        "\n",
        "nodes = [\n",
        "    (\"init_research\", initialize_research),\n",
        "    (\"conduct_interviews\", conduct_interviews),\n",
        "    (\"refine_outline\", refine_outline),\n",
        "    (\"index_references\", index_references),\n",
        "    (\"write_sections\", write_sections),\n",
        "    (\"write_article\", write_article),\n",
        "]\n",
        "for i in range(len(nodes)):\n",
        "    name, node = nodes[i]\n",
        "    builder.add_node(name, node, retry=RetryPolicy(max_attempts=3))\n",
        "    if i > 0:\n",
        "        builder.add_edge(nodes[i - 1][0], name)\n",
        "\n",
        "builder.add_edge(START, nodes[0][0])\n",
        "builder.add_edge(nodes[-1][0], END)\n",
        "storm = builder.compile(checkpointer=MemorySaver())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBP4OwIxFi9F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26eb623c-1d04-4f02-e32e-e37ab12b85a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "init_research\n",
            "--  {'topic': '熱・風以外の方法で髪の毛を乾かす技術のトレンドを教えて', 'outline': Outline(page_title='熱・風以外の髪の毛を乾かす技術', sections=[Section(section_title='はじめに', description='髪の毛を乾かす方法は、従来の熱や風を利用する方法に加え、最近ではさまざまな新しい技術が登場しています。これらは髪に優しく、ダメージを最小限に抑えることが目的とされています。特に、熱や風を使わない方法は、髪の健康を重視する消費者から注目されているトレンドです。特に環境に優しい製品や、効率的に水分を除去できる技術が求\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-938fd75fcdcb>:32: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  message = HumanMessage(**message.dict(exclude={\"type\"}))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting scholarly search...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-938fd75fcdcb>:32: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  message = HumanMessage(**message.dict(exclude={\"type\"}))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting scholarly search...\n",
            "Starting scholarly search...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-938fd75fcdcb>:32: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  message = HumanMessage(**message.dict(exclude={\"type\"}))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting web search...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-938fd75fcdcb>:32: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  message = HumanMessage(**message.dict(exclude={\"type\"}))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting web search...\n",
            "Starting web search...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-938fd75fcdcb>:32: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  message = HumanMessage(**message.dict(exclude={\"type\"}))\n",
            "<ipython-input-14-938fd75fcdcb>:32: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  message = HumanMessage(**message.dict(exclude={\"type\"}))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting scholarly search...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-938fd75fcdcb>:32: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  message = HumanMessage(**message.dict(exclude={\"type\"}))\n",
            "<ipython-input-14-938fd75fcdcb>:32: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  message = HumanMessage(**message.dict(exclude={\"type\"}))\n",
            "<ipython-input-14-938fd75fcdcb>:32: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  message = HumanMessage(**message.dict(exclude={\"type\"}))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting scholarly search...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-938fd75fcdcb>:32: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  message = HumanMessage(**message.dict(exclude={\"type\"}))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting scholarly search...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-938fd75fcdcb>:32: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  message = HumanMessage(**message.dict(exclude={\"type\"}))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting web search...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-938fd75fcdcb>:32: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  message = HumanMessage(**message.dict(exclude={\"type\"}))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting web search...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-938fd75fcdcb>:32: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  message = HumanMessage(**message.dict(exclude={\"type\"}))\n",
            "<ipython-input-14-938fd75fcdcb>:32: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  message = HumanMessage(**message.dict(exclude={\"type\"}))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting web search...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-938fd75fcdcb>:32: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  message = HumanMessage(**message.dict(exclude={\"type\"}))\n",
            "<ipython-input-14-938fd75fcdcb>:32: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  message = HumanMessage(**message.dict(exclude={\"type\"}))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting scholarly search...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-938fd75fcdcb>:32: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  message = HumanMessage(**message.dict(exclude={\"type\"}))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting scholarly search...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-938fd75fcdcb>:32: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  message = HumanMessage(**message.dict(exclude={\"type\"}))\n",
            "<ipython-input-14-938fd75fcdcb>:32: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  message = HumanMessage(**message.dict(exclude={\"type\"}))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting scholarly search...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-938fd75fcdcb>:32: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  message = HumanMessage(**message.dict(exclude={\"type\"}))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting web search...\n",
            "Starting web search...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-938fd75fcdcb>:32: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  message = HumanMessage(**message.dict(exclude={\"type\"}))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting web search...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-938fd75fcdcb>:32: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  message = HumanMessage(**message.dict(exclude={\"type\"}))\n",
            "<ipython-input-14-938fd75fcdcb>:32: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  message = HumanMessage(**message.dict(exclude={\"type\"}))\n",
            "<ipython-input-14-938fd75fcdcb>:32: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  message = HumanMessage(**message.dict(exclude={\"type\"}))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting scholarly search...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-938fd75fcdcb>:32: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  message = HumanMessage(**message.dict(exclude={\"type\"}))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting scholarly search...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-938fd75fcdcb>:32: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  message = HumanMessage(**message.dict(exclude={\"type\"}))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting web search...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-938fd75fcdcb>:32: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  message = HumanMessage(**message.dict(exclude={\"type\"}))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting web search...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-938fd75fcdcb>:32: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  message = HumanMessage(**message.dict(exclude={\"type\"}))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conduct_interviews\n",
            "--  {'topic': '熱・風以外の方法で髪の毛を乾かす技術のトレンドを教えて', 'outline': Outline(page_title='熱・風以外の髪の毛を乾かす技術', sections=[Section(section_title='はじめに', description='髪の毛を乾かす方法は、従来の熱や風を利用する方法に加え、最近ではさまざまな新しい技術が登場しています。これらは髪に優しく、ダメージを最小限に抑えることが目的とされています。特に、熱や風を使わない方法は、髪の健康を重視する消費者から注目されているトレンドです。特に環境に優しい製品や、効率的に水分を除去できる技術が求\n",
            "refine_outline\n",
            "--  {'topic': '熱・風以外の方法で髪の毛を乾かす技術のトレンドを教えて', 'outline': Outline(page_title='熱・風以外の髪の毛を乾かす技術', sections=[Section(section_title='はじめに', description='従来の熱や風を利用する方法に加え、最近では熱・風以外で髪の毛を乾かす新しい技術が多数登場しています。これらの技術は、髪の健康を重視し、より優れた仕上がりと環境への配慮を実現することを目的としています。特に、消費者の間では、髪へのダメージを最小限に抑える選択肢が求められています。近年のトレンドには、超音波技術、マイ\n",
            "index_references\n",
            "--  {'topic': '熱・風以外の方法で髪の毛を乾かす技術のトレンドを教えて', 'outline': Outline(page_title='熱・風以外の髪の毛を乾かす技術', sections=[Section(section_title='はじめに', description='従来の熱や風を利用する方法に加え、最近では熱・風以外で髪の毛を乾かす新しい技術が多数登場しています。これらの技術は、髪の健康を重視し、より優れた仕上がりと環境への配慮を実現することを目的としています。特に、消費者の間では、髪へのダメージを最小限に抑える選択肢が求められています。近年のトレンドには、超音波技術、マイ\n",
            "write_sections\n",
            "--  {'topic': '熱・風以外の方法で髪の毛を乾かす技術のトレンドを教えて', 'outline': Outline(page_title='熱・風以外の髪の毛を乾かす技術', sections=[Section(section_title='はじめに', description='従来の熱や風を利用する方法に加え、最近では熱・風以外で髪の毛を乾かす新しい技術が多数登場しています。これらの技術は、髪の健康を重視し、より優れた仕上がりと環境への配慮を実現することを目的としています。特に、消費者の間では、髪へのダメージを最小限に抑える選択肢が求められています。近年のトレンドには、超音波技術、マイ\n",
            "write_article\n",
            "--  {'topic': '熱・風以外の方法で髪の毛を乾かす技術のトレンドを教えて', 'outline': Outline(page_title='熱・風以外の髪の毛を乾かす技術', sections=[Section(section_title='はじめに', description='従来の熱や風を利用する方法に加え、最近では熱・風以外で髪の毛を乾かす新しい技術が多数登場しています。これらの技術は、髪の健康を重視し、より優れた仕上がりと環境への配慮を実現することを目的としています。特に、消費者の間では、髪へのダメージを最小限に抑える選択肢が求められています。近年のトレンドには、超音波技術、マイ\n"
          ]
        }
      ],
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"my-thread\"}}\n",
        "async for step in storm.astream({\"topic\": topic}, config):\n",
        "    name = next(iter(step))\n",
        "    print(name)\n",
        "    print(\"-- \", str(step[name])[:300])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EyxUIekuFi9F"
      },
      "outputs": [],
      "source": [
        "checkpoint = storm.get_state(config)\n",
        "article = checkpoint.values[\"article\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0E95CBhFi9G"
      },
      "source": [
        "# Wikiのレンダリング\n",
        "\n",
        "これで最終的なwikiページをレンダリングできます！"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown\n",
        "\n",
        "# We will down-header the sections to create less confusion in this notebook\n",
        "Markdown(article.replace(\"\\n#\", \"\\n##\"))"
      ],
      "metadata": {
        "id": "HilLquaLX9Z1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 695
        },
        "outputId": "b6a259ba-0c59-4953-b383-1e1060a5299c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# 熱・風以外の髪の毛乾燥技術\n\n### はじめに\n\n従来の熱や風を利用する方法に加え、最近では熱・風以外で髪の毛を乾かす新しい技術が多数登場しています。これらの技術は、髪の健康を重視し、より優れた仕上がりと環境への配慮を実現することを目的としています。特に、消費者の間では、髪へのダメージを最小限に抑える選択肢が求められています。近年のトレンドには、超音波技術、マイクロミスト技術、イオン技術、ナノファイバー技術など様々な革新が含まれています。これにより、消費者は髪を効率的に乾かしながら、髪質を改善する製品を求めるようになっています。\n\n### 主な技術\n\n#### 超音波技術\n\n超音波技術は、音波を利用して水分を細かく分散させる方法です。この技術により、髪の毛内部の水分が効果的に蒸発し、乾燥が促進されます。超音波による振動は、髪の毛に優しく、ダメージを抑えつつ効率的に乾燥することができます。\n\n#### マイクロミスト技術\n\nマイクロミスト技術は、非常に細かい水の粒子を細かく噴射するシステムです。これにより、髪の毛表面から均等に水分が蒸発し、乾燥時間を短縮します。この技術は、髪への負担を軽減しながら、仕上がりのツヤや手触りにも大きな影響を与えます。\n\n#### イオン技術\n\nイオン技術は、髪に正負のイオンを届けることで、静電気を除去し、髪の毛の乾燥を助ける方法です。イオンが髪の毛に潤いをもたらし、スタイリングの際のダメージを軽減します。近年では、イオン技術を搭載したドライヤーやスタイリングツールが多く登場しています。\n\n#### ナノファイバー技術\n\nナノファイバー技術は、ナノレベルの繊維を用いて水分を効果的に吸収する技術です。この繊維は非常に高い吸水性を持ち、髪の毛表面から水分を迅速に取り除くことが可能です。ナノファイバー技術を利用したタオルやマントなどの製品が人気です。\n\n### 結論\n\n熱や風を使用せずに髪を乾かす新しい技術は、髪の健康を重視し、効率的かつ環境に優しい方法として注目を集めています。消費者はこれらの革新を通じて、髪に優しい乾燥方法を選択することで、より良いヘアケアを実現できるようになっています。\n\n---\n\n[1] https://www.demi.nicca.co.jp/media/904/  \n[2] https://quickpcr.jp/contents/other/hairdry/  \n[3] https://bihadashop.jp/entry/air-dry  \n[4] https://www.livedoor.com/choice/haircare_tips-natural-drying/"
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rQ4bcBP36_92"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}